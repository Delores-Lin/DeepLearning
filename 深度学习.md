## 多类分类
* 对类别进行一位有效编码：
  $$
    y = [y_1,y_2,\cdots ,y_n]^T\\

    y_i=\left\{
    \begin{align*}
    &1 && if&i=y\\
    \\
    &0 && otherwise
    \end{align*}
    \right.
    $$
    每个样本本中只有一个真实值，其值为1，其余都为0
* 使用均方损失训练
* 最大值最为预测
  $$
  \hat y = \mathop{argmax}\limits_{i}o_i 
  $$

## Softmax回归
$$
\hat y = softmax(o)\\
\hat y_i = \frac{exp(o_i)}{\sum_k exp(o_k)}
$$
其中$exp(o_i)$表示$e^{o_i}$  

## 损失函数
### L2 Loss 均方损失
$$
l(y,y') = \frac{1}{2}(y-y')^2
$$
### L1 Loss
$$
l(y,y')=|y-y'|
$$

### 交叉熵损失
* 交叉熵常用来衡量两个概率的区别
  $$H(p,q) = \sum_i -p_ilog(q_i)$$
* 将它作为损失
  $$l(y,\hat y) = - \sum_i y_i log\hat y_i = -log\hat y_y$$
  (因为其余项全为0)
* 其梯度是真实概率和预测概率的区别
  $$
  \partial_{o_i}l(y,\hat y) = softmax(o)_i - y_i
  $$

### Sigmoid 激活函数
* 将输入投影到`(0,1)`
  $$
  \mathop{Sigmoid(x)} = \frac{1}{1 + exp(-x)}
  $$
* ![alt text](image.png)
### Tanh 激活函数
* 将输入投影到`(-1,1)`
  $$
  \mathop{tanh(x)} = \frac{1 - exp(-2x)}{1 + exp(-2x)}
  $$
* ![alt text](image-1.png)

### ReLU 激活函数
* ReLU:rectified linear unit
  $$
  \mathop{ReLU(x)} = max(x,0)
  $$